_wandb:
    value:
        cli_version: 0.22.2
        e:
            3rijwh5gxje9gn6kfsxt9xh210up3wtw:
                codePath: src/batch_evaluate.py
                codePathLocal: batch_evaluate.py
                cpu_count: 4
                cpu_count_logical: 8
                cudaVersion: "12.8"
                disk:
                    /:
                        total: "520120602624"
                        used: "166995705856"
                email: sllmdj05@gmail.com
                executable: /home/sllmdj05/.pyenv/versions/third/bin/python
                git:
                    commit: 675634927b0facded23e3804ece07a78c8ab3d95
                    remote: https://github.com/sllm05/3rd_project.git
                gpu: Tesla V100-SXM2-16GB
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Volta
                      cudaCores: 5120
                      memoryTotal: "17179869184"
                      name: Tesla V100-SXM2-16GB
                      uuid: GPU-f17be017-91a2-6af4-8438-0493e29b77fb
                host: instance-20251021-025950
                memory:
                    total: "31538257920"
                os: Linux-6.8.0-1041-gcp-x86_64-with-glibc2.35
                program: /home/sllmdj05/3rd_project/src/batch_evaluate.py
                python: CPython 3.11.8
                root: /home/sllmdj05/3rd_project/src
                startedAt: "2025-10-21T09:52:11.544474Z"
                writerId: 3rijwh5gxje9gn6kfsxt9xh210up3wtw
        m: []
        python_version: 3.11.8
        t:
            "1":
                - 1
                - 5
                - 11
                - 49
                - 51
                - 53
                - 71
                - 98
                - 100
            "2":
                - 1
                - 5
                - 11
                - 49
                - 51
                - 53
                - 71
                - 98
                - 100
            "3":
                - 2
                - 13
                - 16
                - 24
            "4": 3.11.8
            "5": 0.22.2
            "6": 4.57.1
            "12": 0.22.2
            "13": linux-x86_64
model:
    value: LGAI-EXAONE/EXAONE-Deep-7.8B
